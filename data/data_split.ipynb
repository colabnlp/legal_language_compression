{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this script is to split the raw legislation compressions dataset into train, validation and test sets. The order of the legislation compression dataset has not be randomised before now, so we do so here. The script also defines the split for the 'targetted' train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'legislative_compressions_tsv.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a dictionary\n",
    "\n",
    "def _read_leg_compressions(filename):\n",
    "    with open(filename, newline='') as tabfile:\n",
    "        count = 0\n",
    "        full_data = {}\n",
    "        legReader = csv.reader(tabfile, delimiter = '\\t', quotechar = '\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        next(legReader, None)\n",
    "        for row in legReader:\n",
    "            reference = row[0] # legislative reference\n",
    "            full_text = row[1] # uncompressed text\n",
    "            compressed_text = row[2] # compressed text\n",
    "            target = row[3] # entry part of targetted sub-set\n",
    "            fragment = row[4] # fragment or whole sentence\n",
    "            concat = row[5] # stand alone provision or concatenation\n",
    "            if full_text[-1] == \"\\n\":\n",
    "                full_text = full_text[:-1]\n",
    "            if compressed_text[-1] == \"\\n\":\n",
    "                compressed_text = compressed_text[:-1]\n",
    "            full_data[count] = {\n",
    "                'reference': reference,\n",
    "                'full_text': full_text,\n",
    "                'compressed_text': compressed_text,\n",
    "                'target': target,\n",
    "                'fragment': fragment,\n",
    "                'concat': concat\n",
    "            }\n",
    "            count += 1\n",
    "        return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = _read_leg_compressions(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to get some random indexes\n",
    "\n",
    "idx = list(range(len(full_data)))\n",
    "np.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, val and test split\n",
    "\n",
    "train_data = idx[0:750]\n",
    "val_data = idx[750:850]\n",
    "test_data = idx[850:]\n",
    "\n",
    "train_dict = {}\n",
    "val_dict = {}\n",
    "test_dict = {}\n",
    "\n",
    "for i in train_data:\n",
    "    train_dict[i] = full_data[i]\n",
    "for i in val_data:\n",
    "    val_dict[i] = full_data[i]\n",
    "for i in test_data:\n",
    "    test_dict[i] = full_data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write pickle outputs\n",
    "\n",
    "train_file = \"leg_train_data.pickle\"\n",
    "val_file = \"leg_val_data.pickle\"\n",
    "test_file = \"leg_test_data.pickle\"\n",
    "\n",
    "with open(train_file, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(train_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(val_file, 'wb') as f:\n",
    "    pickle.dump(val_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(test_file, 'wb') as f:\n",
    "    pickle.dump(test_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targetted train and val split\n",
    "\n",
    "train_targetted_dict = {}\n",
    "val_targetted_dict = {}\n",
    "\n",
    "for i in train_data:\n",
    "    if full_data[i]['target'] == \"Yes\":\n",
    "        train_targetted_dict[i] = full_data[i]\n",
    "for i in val_data:\n",
    "    if full_data[i]['target'] == \"Yes\":\n",
    "        val_targetted_dict[i] = full_data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write pickle outputs\n",
    "\n",
    "targetted_train_file = \"leg_targetted_train_data.pickle\"\n",
    "targetted_val_file = \"leg_targetted_val_data.pickle\"\n",
    "\n",
    "with open(targetted_train_file, 'wb') as f:\n",
    "    pickle.dump(train_targetted_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(targetted_val_file, 'wb') as f:\n",
    "    pickle.dump(val_targetted_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
